# Deep Learning Coursework Labs

This repository contains my coursework labs for the **Deep Learning** course. Each lab focuses on a fundamental concept or technique in deep learning, ranging from basic loss functions to advanced generative models.  

## Contents

- **Lab 1: Mean Square Error (MSE)**  
  Introduction to regression loss functions. Implemented mean square error and explored how it drives optimization in simple models.  

- **Lab 2: Linear Regression**  
  Building and training a linear regression model with gradient descent. Visualizing the effect of learning rate and convergence.  

- **Lab 3: Recurrent Neural Networks (RNNs)**  
  Sequential data modeling with simple RNNs. Applications discussed include text data and sequence predictions.  

- **Lab 4: Long Short-Term Memory (LSTM)**  
  Implementing LSTMs to address vanishing gradient problems in traditional RNNs. Hands-on experiments with sequence learning tasks.  

- **Lab 5: Convolutional Neural Networks (CNNs)**  
  Image classification using convolutional architectures. Includes layers such as convolution, pooling, and fully connected layers.  

- **Lab 6: Transfer Learning**  
  Applying pre-trained models (e.g., ResNet, VGG) on new datasets. Fine-tuning vs feature extraction.  

- **Lab 7: Machine Translation**  
  Sequence-to-sequence models for translating text between languages using encoder-decoder architectures.  

- **Lab 8: Generative Adversarial Networks (GANs)**  
  Implementing GANs to generate synthetic data. Training dynamics between generator and discriminator explored.  

## Tech Stack

- **Languages**: Python  
- **Frameworks/Libraries**: PyTorch / TensorFlow, NumPy, Matplotlib, SciKit-Learn , Keras
- **Tools**: Jupyter Notebooks  


