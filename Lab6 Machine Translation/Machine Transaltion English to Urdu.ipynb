{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "execution": {
          "iopub.execute_input": "2024-04-21T15:42:48.143272Z",
          "iopub.status.busy": "2024-04-21T15:42:48.142575Z",
          "iopub.status.idle": "2024-04-21T15:42:53.322589Z",
          "shell.execute_reply": "2024-04-21T15:42:53.321827Z",
          "shell.execute_reply.started": "2024-04-21T14:16:52.430621Z"
        },
        "papermill": {
          "duration": 5.22467,
          "end_time": "2024-04-21T15:42:53.322704",
          "exception": false,
          "start_time": "2024-04-21T15:42:48.098034",
          "status": "completed"
        },
        "tags": [],
        "collapsed": true,
        "id": "g93pDSJGWA7X",
        "outputId": "a860297e-53dd-432e-fbf2-c212c864b21f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/kaggle/input/english-urdu/Quran-UR (1)\n",
            "/kaggle/input/english-urdu/Quran-EN (1)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import unicodedata\n",
        "import re\n",
        "import numpy as np\n",
        "import time\n",
        "import string\n",
        "\n",
        "\n",
        "from plotly.offline import init_notebook_mode, iplot\n",
        "import plotly.graph_objs as go\n",
        "\n",
        "import os\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "execution": {
          "iopub.execute_input": "2024-04-21T15:42:53.577696Z",
          "iopub.status.busy": "2024-04-21T15:42:53.577073Z",
          "iopub.status.idle": "2024-04-21T15:42:53.715320Z",
          "shell.execute_reply": "2024-04-21T15:42:53.715916Z",
          "shell.execute_reply.started": "2024-04-21T14:16:52.443068Z"
        },
        "papermill": {
          "duration": 0.186569,
          "end_time": "2024-04-21T15:42:53.716083",
          "exception": false,
          "start_time": "2024-04-21T15:42:53.529514",
          "status": "completed"
        },
        "tags": [],
        "id": "krAywcPHWA7Y"
      },
      "outputs": [],
      "source": [
        "with open('/content/Quran-EN (1)', 'r', encoding='utf-8') as file:\n",
        "    english_text = file.read().splitlines()\n",
        "\n",
        "with open('/content/Quran-UR (1)', 'r', encoding='utf-8') as file:\n",
        "    urdu_text = file.read().splitlines()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-21T15:42:53.808455Z",
          "iopub.status.busy": "2024-04-21T15:42:53.807561Z",
          "iopub.status.idle": "2024-04-21T15:42:53.811442Z",
          "shell.execute_reply": "2024-04-21T15:42:53.810770Z",
          "shell.execute_reply.started": "2024-04-21T14:16:52.467939Z"
        },
        "papermill": {
          "duration": 0.05171,
          "end_time": "2024-04-21T15:42:53.811559",
          "exception": false,
          "start_time": "2024-04-21T15:42:53.759849",
          "status": "completed"
        },
        "tags": [],
        "id": "45bDJN2gWA7Y",
        "outputId": "eff459a9-cb7d-4875-ee2d-bafd8f6abc2b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Englist Text records:  6414 , Urdu Text records:  6414\n"
          ]
        }
      ],
      "source": [
        "print(\"Englist Text records: \",len(english_text), ', Urdu Text records: ' ,len(urdu_text))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-21T15:42:53.893402Z",
          "iopub.status.busy": "2024-04-21T15:42:53.892500Z",
          "iopub.status.idle": "2024-04-21T15:42:53.895441Z",
          "shell.execute_reply": "2024-04-21T15:42:53.894819Z",
          "shell.execute_reply.started": "2024-04-21T14:16:52.474354Z"
        },
        "papermill": {
          "duration": 0.045035,
          "end_time": "2024-04-21T15:42:53.895536",
          "exception": false,
          "start_time": "2024-04-21T15:42:53.850501",
          "status": "completed"
        },
        "tags": [],
        "id": "739uYBRtWA7Z"
      },
      "outputs": [],
      "source": [
        "exclude = set(string.punctuation) #\n",
        "remove_digits = str.maketrans('', '', string.digits)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-21T15:42:53.978600Z",
          "iopub.status.busy": "2024-04-21T15:42:53.977889Z",
          "iopub.status.idle": "2024-04-21T15:42:53.980416Z",
          "shell.execute_reply": "2024-04-21T15:42:53.979925Z",
          "shell.execute_reply.started": "2024-04-21T14:16:52.484118Z"
        },
        "papermill": {
          "duration": 0.047124,
          "end_time": "2024-04-21T15:42:53.980514",
          "exception": false,
          "start_time": "2024-04-21T15:42:53.933390",
          "status": "completed"
        },
        "tags": [],
        "id": "HR5L0proWA7Z"
      },
      "outputs": [],
      "source": [
        "def preprocess_eng_sentence(sent):\n",
        "    '''Function to preprocess English sentence'''\n",
        "    sent = sent.lower()\n",
        "    sent = re.sub(\"'\", '', sent)\n",
        "    sent = ''.join(ch for ch in sent if ch not in exclude)\n",
        "    sent = sent.translate(remove_digits)\n",
        "    sent = sent.strip()\n",
        "    sent = re.sub(\" +\", \" \", sent)\n",
        "    sent = '<start> ' + sent + ' <end>'\n",
        "    return sent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-21T15:42:54.063073Z",
          "iopub.status.busy": "2024-04-21T15:42:54.062288Z",
          "iopub.status.idle": "2024-04-21T15:42:54.064907Z",
          "shell.execute_reply": "2024-04-21T15:42:54.064355Z",
          "shell.execute_reply.started": "2024-04-21T14:16:52.494797Z"
        },
        "papermill": {
          "duration": 0.045677,
          "end_time": "2024-04-21T15:42:54.065011",
          "exception": false,
          "start_time": "2024-04-21T15:42:54.019334",
          "status": "completed"
        },
        "tags": [],
        "id": "sCvx4mQ1WA7Z"
      },
      "outputs": [],
      "source": [
        "urdu_diacritics  = ['ِ', 'ٰ', 'ُ', 'ٍ', 'ً', 'َ']\n",
        "\n",
        "def remove_diacritics(text):\n",
        "    for letter in text:\n",
        "\n",
        "        if letter in urdu_diacritics:\n",
        "            text = text.replace(letter, '')\n",
        "    return text\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-21T15:42:54.148712Z",
          "iopub.status.busy": "2024-04-21T15:42:54.148130Z",
          "iopub.status.idle": "2024-04-21T15:42:54.150832Z",
          "shell.execute_reply": "2024-04-21T15:42:54.150259Z",
          "shell.execute_reply.started": "2024-04-21T14:16:52.503919Z"
        },
        "papermill": {
          "duration": 0.047878,
          "end_time": "2024-04-21T15:42:54.150944",
          "exception": false,
          "start_time": "2024-04-21T15:42:54.103066",
          "status": "completed"
        },
        "tags": [],
        "id": "-IJW7O_PWA7Z"
      },
      "outputs": [],
      "source": [
        "urdu_digits = ['۶', '۴', '۵', '۸', '۲', '۰', '۷', '۹', '۳', '۱']\n",
        "\n",
        "english_digits=['1','2','3','4','5','6','7','8','9','0']\n",
        "\n",
        "def remove_numbers(text):\n",
        "    for letter in text:\n",
        "        if letter in urdu_digits or letter in english_digits :\n",
        "            text = text.replace(letter, '')\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-21T15:42:54.233770Z",
          "iopub.status.busy": "2024-04-21T15:42:54.233125Z",
          "iopub.status.idle": "2024-04-21T15:42:54.236361Z",
          "shell.execute_reply": "2024-04-21T15:42:54.235739Z",
          "shell.execute_reply.started": "2024-04-21T14:16:52.513793Z"
        },
        "papermill": {
          "duration": 0.047138,
          "end_time": "2024-04-21T15:42:54.236456",
          "exception": false,
          "start_time": "2024-04-21T15:42:54.189318",
          "status": "completed"
        },
        "tags": [],
        "id": "-vT0y8-MWA7a"
      },
      "outputs": [],
      "source": [
        "def preprocess_ur_sentence(sent):\n",
        "  sent = re.sub(\"'\", '', sent)\n",
        "  sent = remove_diacritics(sent)\n",
        "  sent = re.sub(r'[؛۔٫٪+=@#!؟،۔)(}{]', '',sent)\n",
        "  sent = remove_numbers(sent)\n",
        "  sent = sent.strip()\n",
        "  sent = re.sub(\" +\", \" \", sent)\n",
        "  sent = '<start> ' + sent + ' <end>'\n",
        "  return sent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-21T15:42:54.366278Z",
          "iopub.status.busy": "2024-04-21T15:42:54.329944Z",
          "iopub.status.idle": "2024-04-21T15:42:55.463674Z",
          "shell.execute_reply": "2024-04-21T15:42:55.464245Z",
          "shell.execute_reply.started": "2024-04-21T14:16:52.527406Z"
        },
        "papermill": {
          "duration": 1.189937,
          "end_time": "2024-04-21T15:42:55.464383",
          "exception": false,
          "start_time": "2024-04-21T15:42:54.274446",
          "status": "completed"
        },
        "tags": [],
        "id": "cC7yS1fWWA7a",
        "outputId": "fbaf07e9-7551-4416-fa75-3abc8aca4f28"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[['<start> and before that he destroyed the people of nuh noah as well surely they were extremely wicked and exceedingly defiant <end>',\n",
              "  '<start> اور اس سے پہلے قوم نوح کو بھی ہلاک کیا بیشک وہ بڑے ہی ظالم اور بڑے ہی سرکش تھے <end>'],\n",
              " ['<start> and he is the one who raised up the overturned towns of the people of lut lot and smashed them down <end>',\n",
              "  '<start> اور قوم لوط کی الٹی ہوئی بستیوں کو اوپر اٹھا کر اسی نے نیچے دے پٹکا <end>'],\n",
              " ['<start> then that covered them which did cover i e the stones were rained on them <end>',\n",
              "  '<start> پس ان کو ڈھانپ لیا جس نے ڈھانپ لیا یعنی پھر ان پر پتھروں کی بارش کر دی گئی <end>'],\n",
              " ['<start> so o man which of the favours of your lord will you doubt <end>',\n",
              "  '<start> سو اے انسان تو اپنے پروردگار کی کن کن نعمتوں میں شک کرے گا <end>'],\n",
              " ['<start> this holy prophet blessings and peace be upon him is also a warner of the warners of old <end>',\n",
              "  '<start> یہ رسول اکرم صلی اللہ علیہ وآلہ وسلم بھی اگلے ڈر سنانے والوں میں سے ایک ڈر سنانے والے ہیں <end>'],\n",
              " ['<start> the imminent hour of judgment has drawn near <end>',\n",
              "  '<start> آنے والی قیامت کی گھڑی قریب آپہنچی <end>'],\n",
              " ['<start> no one except allah can bring it forth and establish <end>',\n",
              "  '<start> اﷲ کے سوا اسے کوئی ظاہر اور قائم کرنے والا نہیں ہے <end>'],\n",
              " ['<start> so do you wonder at this revelation <end>',\n",
              "  '<start> پس کیا تم اس کلام سے تعجب کرتے ہو <end>'],\n",
              " ['<start> and do you laugh and not weep <end>',\n",
              "  '<start> اور تم ہنستے ہو اور روتے نہیں ہو <end>'],\n",
              " ['<start> while you are busy playing a game of negligence <end>',\n",
              "  '<start> اور تم غفلت کی کھیل میں پڑے ہو <end>']]"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sent_pairs = []\n",
        "for eng, ur in zip(english_text, urdu_text):\n",
        "    eng = preprocess_eng_sentence(eng)\n",
        "    ur = preprocess_ur_sentence(ur)\n",
        "    sent_pair = [eng, ur]\n",
        "    sent_pairs.append(sent_pair)\n",
        "sent_pairs[5000:5010]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-21T15:42:55.550216Z",
          "iopub.status.busy": "2024-04-21T15:42:55.549344Z",
          "iopub.status.idle": "2024-04-21T15:42:55.552359Z",
          "shell.execute_reply": "2024-04-21T15:42:55.551558Z",
          "shell.execute_reply.started": "2024-04-21T14:16:53.673214Z"
        },
        "papermill": {
          "duration": 0.049661,
          "end_time": "2024-04-21T15:42:55.552482",
          "exception": false,
          "start_time": "2024-04-21T15:42:55.502821",
          "status": "completed"
        },
        "tags": [],
        "id": "uhgFPa7KWA7a"
      },
      "outputs": [],
      "source": [
        "\n",
        "class LanguageIndex():\n",
        "    def __init__(self, lang):\n",
        "        self.lang = lang\n",
        "        self.word2idx = {}\n",
        "        self.idx2word = {}\n",
        "        self.vocab = set()\n",
        "\n",
        "        self.create_index()\n",
        "\n",
        "    def create_index(self):\n",
        "        for phrase in self.lang:\n",
        "            self.vocab.update(phrase.split(' '))\n",
        "\n",
        "        self.vocab = sorted(self.vocab)\n",
        "\n",
        "        self.word2idx['<pad>'] = 0\n",
        "        for index, word in enumerate(self.vocab):\n",
        "            self.word2idx[word] = index + 1\n",
        "\n",
        "        for word, index in self.word2idx.items():\n",
        "            self.idx2word[index] = word"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-21T15:42:55.633464Z",
          "iopub.status.busy": "2024-04-21T15:42:55.632595Z",
          "iopub.status.idle": "2024-04-21T15:42:55.635355Z",
          "shell.execute_reply": "2024-04-21T15:42:55.634720Z",
          "shell.execute_reply.started": "2024-04-21T14:16:53.683651Z"
        },
        "papermill": {
          "duration": 0.044511,
          "end_time": "2024-04-21T15:42:55.635448",
          "exception": false,
          "start_time": "2024-04-21T15:42:55.590937",
          "status": "completed"
        },
        "tags": [],
        "id": "fKsH5fV_WA7a"
      },
      "outputs": [],
      "source": [
        "def max_length(tensor):\n",
        "    return max(len(t) for t in tensor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-21T15:42:55.800191Z",
          "iopub.status.busy": "2024-04-21T15:42:55.799291Z",
          "iopub.status.idle": "2024-04-21T15:42:55.801626Z",
          "shell.execute_reply": "2024-04-21T15:42:55.802225Z",
          "shell.execute_reply.started": "2024-04-21T14:16:53.692883Z"
        },
        "papermill": {
          "duration": 0.051928,
          "end_time": "2024-04-21T15:42:55.802339",
          "exception": false,
          "start_time": "2024-04-21T15:42:55.750411",
          "status": "completed"
        },
        "tags": [],
        "id": "bXBcDy-BWA7a"
      },
      "outputs": [],
      "source": [
        "def load_dataset(pairs, num_examples):\n",
        "\n",
        "    inp_lang = LanguageIndex(en for en, ma in pairs)\n",
        "    targ_lang = LanguageIndex(ma for en, ma in pairs)\n",
        "\n",
        "    input_tensor = [[inp_lang.word2idx[s] for s in en.split(' ')] for en, ma in pairs]\n",
        "\n",
        "\n",
        "    target_tensor = [[targ_lang.word2idx[s] for s in ma.split(' ')] for en, ma in pairs]\n",
        "\n",
        "\n",
        "    max_length_inp, max_length_tar = max_length(input_tensor), max_length(target_tensor)\n",
        "\n",
        "\n",
        "    input_tensor = tf.keras.preprocessing.sequence.pad_sequences(input_tensor,\n",
        "                                                                 maxlen=max_length_inp,\n",
        "                                                                 padding='post')\n",
        "\n",
        "    target_tensor = tf.keras.preprocessing.sequence.pad_sequences(target_tensor,\n",
        "                                                                  maxlen=max_length_tar,\n",
        "                                                                  padding='post')\n",
        "\n",
        "    return input_tensor, target_tensor, inp_lang, targ_lang, max_length_inp, max_length_tar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-21T15:42:55.933113Z",
          "iopub.status.busy": "2024-04-21T15:42:55.917585Z",
          "iopub.status.idle": "2024-04-21T15:42:56.243940Z",
          "shell.execute_reply": "2024-04-21T15:42:56.243343Z",
          "shell.execute_reply.started": "2024-04-21T14:16:53.704606Z"
        },
        "papermill": {
          "duration": 0.403464,
          "end_time": "2024-04-21T15:42:56.244063",
          "exception": false,
          "start_time": "2024-04-21T15:42:55.840599",
          "status": "completed"
        },
        "tags": [],
        "id": "aW6kL3KGWA7a"
      },
      "outputs": [],
      "source": [
        "input_tensor, target_tensor, inp_lang, targ_lang, max_length_inp, max_length_targ = load_dataset(sent_pairs, len(english_text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.037928,
          "end_time": "2024-04-21T15:42:56.320894",
          "exception": false,
          "start_time": "2024-04-21T15:42:56.282966",
          "status": "completed"
        },
        "tags": [],
        "id": "iJj3PKFIWA7a"
      },
      "source": [
        "### Creating training and validation sets using an 80-20 split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-21T15:42:56.405544Z",
          "iopub.status.busy": "2024-04-21T15:42:56.404416Z",
          "iopub.status.idle": "2024-04-21T15:42:56.415088Z",
          "shell.execute_reply": "2024-04-21T15:42:56.414436Z",
          "shell.execute_reply.started": "2024-04-21T14:16:54.209451Z"
        },
        "papermill": {
          "duration": 0.056365,
          "end_time": "2024-04-21T15:42:56.415195",
          "exception": false,
          "start_time": "2024-04-21T15:42:56.358830",
          "status": "completed"
        },
        "tags": [],
        "id": "2oUeSVv1WA7b",
        "outputId": "6504b131-6b41-490b-ac10-da68a34efcbe"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(5772, 5772, 642, 642)"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.1, random_state = 101)\n",
        "\n",
        "len(input_tensor_train), len(target_tensor_train), len(input_tensor_val), len(target_tensor_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-21T15:42:58.244608Z",
          "iopub.status.busy": "2024-04-21T15:42:58.233440Z",
          "iopub.status.idle": "2024-04-21T15:42:58.266031Z",
          "shell.execute_reply": "2024-04-21T15:42:58.265250Z",
          "shell.execute_reply.started": "2024-04-21T14:16:54.222181Z"
        },
        "papermill": {
          "duration": 1.811726,
          "end_time": "2024-04-21T15:42:58.266161",
          "exception": false,
          "start_time": "2024-04-21T15:42:56.454435",
          "status": "completed"
        },
        "tags": [],
        "id": "g684Jnx6WA7b"
      },
      "outputs": [],
      "source": [
        "BUFFER_SIZE = len(input_tensor_train)\n",
        "BATCH_SIZE = 4\n",
        "N_BATCH = BUFFER_SIZE//BATCH_SIZE\n",
        "embedding_dim = 32\n",
        "units = 64\n",
        "vocab_inp_size = len(inp_lang.word2idx)\n",
        "vocab_tar_size = len(targ_lang.word2idx)\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train, target_tensor_train)).shuffle(BUFFER_SIZE)\n",
        "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-21T15:42:58.557291Z",
          "iopub.status.busy": "2024-04-21T15:42:58.556282Z",
          "iopub.status.idle": "2024-04-21T15:42:58.559483Z",
          "shell.execute_reply": "2024-04-21T15:42:58.558891Z",
          "shell.execute_reply.started": "2024-04-21T14:16:54.236257Z"
        },
        "papermill": {
          "duration": 0.060864,
          "end_time": "2024-04-21T15:42:58.559601",
          "exception": false,
          "start_time": "2024-04-21T15:42:58.498737",
          "status": "completed"
        },
        "tags": [],
        "id": "gslvUbz7WA7b"
      },
      "outputs": [],
      "source": [
        "def gru(units):\n",
        "\n",
        "    return tf.keras.layers.GRU(units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True,\n",
        "                                   recurrent_activation='sigmoid',\n",
        "                                   recurrent_initializer='glorot_uniform')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-21T15:42:58.846640Z",
          "iopub.status.busy": "2024-04-21T15:42:58.845547Z",
          "iopub.status.idle": "2024-04-21T15:42:58.848951Z",
          "shell.execute_reply": "2024-04-21T15:42:58.848346Z",
          "shell.execute_reply.started": "2024-04-21T14:16:54.246619Z"
        },
        "papermill": {
          "duration": 0.060124,
          "end_time": "2024-04-21T15:42:58.849076",
          "exception": false,
          "start_time": "2024-04-21T15:42:58.788952",
          "status": "completed"
        },
        "tags": [],
        "id": "d0Yy3j1rWA7b"
      },
      "outputs": [],
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.batch_sz = batch_sz\n",
        "        self.enc_units = enc_units\n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "        self.gru = tf.keras.layers.GRU(self.enc_units, return_sequences=True, return_state=True)\n",
        "\n",
        "    def call(self, x, hidden):\n",
        "        x = self.embedding(x)\n",
        "        output, state = self.gru(x, initial_state=hidden)\n",
        "        return output, state\n",
        "\n",
        "\n",
        "    def initialize_hidden_state(self):\n",
        "        return tf.zeros((self.batch_sz, self.enc_units))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-21T15:42:59.052432Z",
          "iopub.status.busy": "2024-04-21T15:42:59.051303Z",
          "iopub.status.idle": "2024-04-21T15:42:59.054556Z",
          "shell.execute_reply": "2024-04-21T15:42:59.053856Z",
          "shell.execute_reply.started": "2024-04-21T14:16:54.258616Z"
        },
        "papermill": {
          "duration": 0.068386,
          "end_time": "2024-04-21T15:42:59.054660",
          "exception": false,
          "start_time": "2024-04-21T15:42:58.986274",
          "status": "completed"
        },
        "tags": [],
        "id": "FglvykuzWA7b"
      },
      "outputs": [],
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.batch_sz = batch_sz\n",
        "        self.dec_units = dec_units\n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "        self.gru = tf.keras.layers.GRU(self.dec_units, return_sequences=True, return_state=True)\n",
        "        self.fc = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "\n",
        "        self.W1 = tf.keras.layers.Dense(self.dec_units)\n",
        "        self.W2 = tf.keras.layers.Dense(self.dec_units)\n",
        "        self.V = tf.keras.layers.Dense(1)\n",
        "\n",
        "    def call(self, x, hidden, enc_output):\n",
        "        hidden_with_time_axis = tf.expand_dims(hidden, 1)\n",
        "\n",
        "\n",
        "        score = self.V(tf.nn.tanh(self.W1(enc_output) + self.W2(hidden_with_time_axis)))\n",
        "\n",
        "\n",
        "        attention_weights = tf.nn.softmax(score, axis=1)\n",
        "\n",
        "\n",
        "        context_vector = attention_weights * enc_output\n",
        "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
        "\n",
        "\n",
        "        x = self.embedding(x)\n",
        "\n",
        "\n",
        "        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
        "\n",
        "\n",
        "        output, state = self.gru(x)\n",
        "\n",
        "\n",
        "        output = tf.reshape(output, (-1, output.shape[2]))\n",
        "\n",
        "\n",
        "        x = self.fc(output)\n",
        "\n",
        "        return x, state, attention_weights\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def initialize_hidden_state(self):\n",
        "        return tf.zeros((self.batch_sz, self.dec_units))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-21T15:42:59.238618Z",
          "iopub.status.busy": "2024-04-21T15:42:59.237661Z",
          "iopub.status.idle": "2024-04-21T15:42:59.604681Z",
          "shell.execute_reply": "2024-04-21T15:42:59.604088Z",
          "shell.execute_reply.started": "2024-04-21T14:16:54.277974Z"
        },
        "papermill": {
          "duration": 0.41616,
          "end_time": "2024-04-21T15:42:59.604819",
          "exception": false,
          "start_time": "2024-04-21T15:42:59.188659",
          "status": "completed"
        },
        "tags": [],
        "id": "FiPOr6bEWA7c"
      },
      "outputs": [],
      "source": [
        "encoder = Encoder(vocab_inp_size, embedding_dim, units, BATCH_SIZE)\n",
        "decoder = Decoder(vocab_tar_size, embedding_dim, units, BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-21T15:42:59.787240Z",
          "iopub.status.busy": "2024-04-21T15:42:59.786395Z",
          "iopub.status.idle": "2024-04-21T15:42:59.789474Z",
          "shell.execute_reply": "2024-04-21T15:42:59.790597Z",
          "shell.execute_reply.started": "2024-04-21T14:16:54.310951Z"
        },
        "papermill": {
          "duration": 0.054614,
          "end_time": "2024-04-21T15:42:59.790826",
          "exception": false,
          "start_time": "2024-04-21T15:42:59.736212",
          "status": "completed"
        },
        "tags": [],
        "id": "-rbQCz4UWA7c"
      },
      "outputs": [],
      "source": [
        "optimizer = tf.optimizers.Adam()\n",
        "\n",
        "def loss_function(real, pred):\n",
        "    mask = 1 - np.equal(real, 0)\n",
        "    loss_ = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=real, logits=pred) * mask\n",
        "    return tf.reduce_mean(loss_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-21T15:42:59.883456Z",
          "iopub.status.busy": "2024-04-21T15:42:59.882628Z",
          "iopub.status.idle": "2024-04-21T15:42:59.885780Z",
          "shell.execute_reply": "2024-04-21T15:42:59.885073Z",
          "shell.execute_reply.started": "2024-04-21T14:16:54.317637Z"
        },
        "papermill": {
          "duration": 0.051822,
          "end_time": "2024-04-21T15:42:59.885929",
          "exception": false,
          "start_time": "2024-04-21T15:42:59.834107",
          "status": "completed"
        },
        "tags": [],
        "id": "jBJVsw-_WA7c"
      },
      "outputs": [],
      "source": [
        "checkpoint_dir = './training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
        "                                 encoder=encoder,\n",
        "                                 decoder=decoder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-21T15:43:00.080946Z",
          "iopub.status.busy": "2024-04-21T15:43:00.080177Z",
          "iopub.status.idle": "2024-04-21T20:56:41.631917Z",
          "shell.execute_reply": "2024-04-21T20:56:41.632426Z",
          "shell.execute_reply.started": "2024-04-21T14:16:54.327909Z"
        },
        "papermill": {
          "duration": 18821.613517,
          "end_time": "2024-04-21T20:56:41.632598",
          "exception": false,
          "start_time": "2024-04-21T15:43:00.019081",
          "status": "completed"
        },
        "tags": [],
        "id": "d44oCi-1WA7c",
        "outputId": "093ee1a9-65db-4bbb-c9d3-e5501d539dd7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 Batch 0 Loss 2.4580\n",
            "Epoch 1 Batch 100 Loss 1.1422\n",
            "Epoch 1 Batch 200 Loss 0.3869\n",
            "Epoch 1 Batch 300 Loss 0.6631\n",
            "Epoch 1 Batch 400 Loss 0.6247\n",
            "Epoch 1 Batch 500 Loss 1.0076\n",
            "Epoch 1 Batch 600 Loss 0.7182\n",
            "Epoch 1 Batch 700 Loss 0.8851\n",
            "Epoch 1 Batch 800 Loss 1.2327\n",
            "Epoch 1 Batch 900 Loss 1.8690\n",
            "Epoch 1 Batch 1000 Loss 1.0796\n",
            "Epoch 1 Batch 1100 Loss 0.8217\n",
            "Epoch 1 Batch 1200 Loss 1.0273\n",
            "Epoch 1 Batch 1300 Loss 0.8986\n",
            "Epoch 1 Batch 1400 Loss 1.0471\n",
            "Epoch 1 Loss 0.9886\n",
            "Time taken for 1 epoch 3660.0839717388153 sec\n",
            "\n",
            "Epoch 2 Batch 0 Loss 1.4979\n",
            "Epoch 2 Batch 100 Loss 1.3642\n",
            "Epoch 2 Batch 200 Loss 1.0835\n",
            "Epoch 2 Batch 300 Loss 0.5646\n",
            "Epoch 2 Batch 400 Loss 0.6851\n",
            "Epoch 2 Batch 500 Loss 1.1060\n",
            "Epoch 2 Batch 600 Loss 0.6160\n",
            "Epoch 2 Batch 700 Loss 0.3555\n",
            "Epoch 2 Batch 800 Loss 0.6045\n",
            "Epoch 2 Batch 900 Loss 0.5625\n",
            "Epoch 2 Batch 1000 Loss 1.1409\n",
            "Epoch 2 Batch 1100 Loss 0.9630\n",
            "Epoch 2 Batch 1200 Loss 0.9945\n",
            "Epoch 2 Batch 1300 Loss 0.8352\n",
            "Epoch 2 Batch 1400 Loss 0.7268\n",
            "Epoch 2 Loss 0.8761\n",
            "Time taken for 1 epoch 3800.9075105190277 sec\n",
            "\n",
            "Epoch 3 Batch 0 Loss 0.6255\n",
            "Epoch 3 Batch 100 Loss 0.5099\n",
            "Epoch 3 Batch 200 Loss 0.9419\n",
            "Epoch 3 Batch 300 Loss 0.6842\n",
            "Epoch 3 Batch 400 Loss 0.6721\n",
            "Epoch 3 Batch 500 Loss 1.1617\n",
            "Epoch 3 Batch 600 Loss 0.8084\n",
            "Epoch 3 Batch 700 Loss 0.5121\n",
            "Epoch 3 Batch 800 Loss 0.6919\n",
            "Epoch 3 Batch 900 Loss 0.5685\n",
            "Epoch 3 Batch 1000 Loss 0.6515\n",
            "Epoch 3 Batch 1100 Loss 0.8768\n",
            "Epoch 3 Batch 1200 Loss 1.0948\n",
            "Epoch 3 Batch 1300 Loss 0.9858\n",
            "Epoch 3 Batch 1400 Loss 0.5984\n",
            "Epoch 3 Loss 0.8043\n",
            "Time taken for 1 epoch 3783.8464872837067 sec\n",
            "\n",
            "Epoch 4 Batch 0 Loss 0.8521\n",
            "Epoch 4 Batch 100 Loss 0.7887\n",
            "Epoch 4 Batch 200 Loss 0.5380\n",
            "Epoch 4 Batch 300 Loss 0.5582\n",
            "Epoch 4 Batch 400 Loss 0.5567\n",
            "Epoch 4 Batch 500 Loss 1.0638\n",
            "Epoch 4 Batch 600 Loss 0.7981\n",
            "Epoch 4 Batch 700 Loss 0.3993\n",
            "Epoch 4 Batch 800 Loss 0.5304\n",
            "Epoch 4 Batch 900 Loss 1.0613\n",
            "Epoch 4 Batch 1000 Loss 0.4256\n",
            "Epoch 4 Batch 1100 Loss 0.6409\n",
            "Epoch 4 Batch 1200 Loss 0.6133\n",
            "Epoch 4 Batch 1300 Loss 0.6040\n",
            "Epoch 4 Batch 1400 Loss 0.9281\n",
            "Epoch 4 Loss 0.7641\n",
            "Time taken for 1 epoch 3793.0306346416473 sec\n",
            "\n",
            "Epoch 5 Batch 0 Loss 1.2439\n",
            "Epoch 5 Batch 100 Loss 1.2875\n",
            "Epoch 5 Batch 200 Loss 0.3284\n",
            "Epoch 5 Batch 300 Loss 0.6945\n",
            "Epoch 5 Batch 400 Loss 0.5635\n",
            "Epoch 5 Batch 500 Loss 0.7694\n",
            "Epoch 5 Batch 600 Loss 0.6480\n",
            "Epoch 5 Batch 700 Loss 1.1088\n",
            "Epoch 5 Batch 800 Loss 0.4587\n",
            "Epoch 5 Batch 900 Loss 1.3668\n",
            "Epoch 5 Batch 1000 Loss 1.4745\n",
            "Epoch 5 Batch 1100 Loss 0.5739\n",
            "Epoch 5 Batch 1200 Loss 0.6422\n",
            "Epoch 5 Batch 1300 Loss 0.5225\n",
            "Epoch 5 Batch 1400 Loss 1.0727\n",
            "Epoch 5 Loss 0.7365\n",
            "Time taken for 1 epoch 3783.6132593154907 sec\n",
            "\n"
          ]
        }
      ],
      "source": [
        "EPOCHS = 5\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    start = time.time()\n",
        "\n",
        "    hidden = encoder.initialize_hidden_state()\n",
        "    total_loss = 0\n",
        "\n",
        "    for (batch, (inp, targ)) in enumerate(dataset):\n",
        "        loss = 0\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "            enc_output, enc_hidden = encoder(inp, hidden)\n",
        "\n",
        "            dec_hidden = enc_hidden\n",
        "\n",
        "            dec_input = tf.expand_dims([targ_lang.word2idx['<start>']] * BATCH_SIZE, 1)\n",
        "\n",
        "\n",
        "            for t in range(1, targ.shape[1]):\n",
        "\n",
        "                predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
        "\n",
        "                loss += loss_function(targ[:, t], predictions)\n",
        "\n",
        "\n",
        "                dec_input = tf.expand_dims(targ[:, t], 1)\n",
        "\n",
        "        batch_loss = (loss / int(targ.shape[1]))\n",
        "\n",
        "        total_loss += batch_loss\n",
        "\n",
        "        variables = encoder.variables + decoder.variables\n",
        "\n",
        "        gradients = tape.gradient(loss, variables)\n",
        "\n",
        "        optimizer.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "        if batch % 100 == 0:\n",
        "            print('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1,\n",
        "                                                         batch,\n",
        "                                                         batch_loss.numpy()))\n",
        "    # saving (checkpoint) the model every epoch\n",
        "    checkpoint.save(file_prefix = checkpoint_prefix)\n",
        "\n",
        "    print('Epoch {} Loss {:.4f}'.format(epoch + 1,\n",
        "                                        total_loss / N_BATCH))\n",
        "    print('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-21T20:56:41.948375Z",
          "iopub.status.busy": "2024-04-21T20:56:41.947517Z",
          "iopub.status.idle": "2024-04-21T20:56:42.046181Z",
          "shell.execute_reply": "2024-04-21T20:56:42.045414Z"
        },
        "papermill": {
          "duration": 0.193718,
          "end_time": "2024-04-21T20:56:42.046338",
          "exception": false,
          "start_time": "2024-04-21T20:56:41.852620",
          "status": "completed"
        },
        "tags": [],
        "collapsed": true,
        "id": "WrVcVW5zWA7i",
        "outputId": "0d197a08-3955-4a0a-ee78-584a16e503d1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7af141ec2a90>"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-21T20:56:42.348466Z",
          "iopub.status.busy": "2024-04-21T20:56:42.347817Z",
          "iopub.status.idle": "2024-04-21T20:56:42.350634Z",
          "shell.execute_reply": "2024-04-21T20:56:42.350035Z"
        },
        "papermill": {
          "duration": 0.082406,
          "end_time": "2024-04-21T20:56:42.350737",
          "exception": false,
          "start_time": "2024-04-21T20:56:42.268331",
          "status": "completed"
        },
        "tags": [],
        "id": "fTR4dM4XWA7i"
      },
      "outputs": [],
      "source": [
        "def evaluate(inputs, encoder, decoder, inp_lang, targ_lang, max_length_inp, max_length_targ):\n",
        "\n",
        "    attention_plot = np.zeros((max_length_targ, max_length_inp))\n",
        "    sentence = ''\n",
        "    for i in inputs[0]:\n",
        "        if i == 0:\n",
        "            break\n",
        "        sentence = sentence + inp_lang.idx2word[i] + ' '\n",
        "    sentence = sentence[:-1]\n",
        "\n",
        "    inputs = tf.convert_to_tensor(inputs)\n",
        "\n",
        "    result = ''\n",
        "\n",
        "    hidden = [tf.zeros((1, units))]\n",
        "    enc_out, enc_hidden = encoder(inputs, hidden)\n",
        "\n",
        "    dec_hidden = enc_hidden\n",
        "    dec_input = tf.expand_dims([targ_lang.word2idx['<start>']], 0)\n",
        "\n",
        "    for t in range(max_length_targ):\n",
        "        predictions, dec_hidden, attention_weights = decoder(dec_input, dec_hidden, enc_out)\n",
        "\n",
        "        # storing the attention weights to plot later on\n",
        "        attention_weights = tf.reshape(attention_weights, (-1, ))\n",
        "        attention_plot[t] = attention_weights.numpy()\n",
        "\n",
        "        predicted_id = tf.argmax(predictions[0]).numpy()\n",
        "\n",
        "        result += targ_lang.idx2word[predicted_id] + ' '\n",
        "\n",
        "        if targ_lang.idx2word[predicted_id] == '<end>':\n",
        "            return result, sentence, attention_plot\n",
        "\n",
        "        # the predicted ID is fed back into the model\n",
        "        dec_input = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "    return result, sentence, attention_plot\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-21T20:56:42.630250Z",
          "iopub.status.busy": "2024-04-21T20:56:42.627148Z",
          "iopub.status.idle": "2024-04-21T20:56:42.633481Z",
          "shell.execute_reply": "2024-04-21T20:56:42.632818Z"
        },
        "papermill": {
          "duration": 0.081483,
          "end_time": "2024-04-21T20:56:42.633587",
          "exception": false,
          "start_time": "2024-04-21T20:56:42.552104",
          "status": "completed"
        },
        "tags": [],
        "id": "a97XvzVhWA7i"
      },
      "outputs": [],
      "source": [
        "def predict_random_val_sentence():\n",
        "    actual_sent = ''\n",
        "    k = np.random.randint(len(input_tensor_val))\n",
        "    random_input = input_tensor_val[k]\n",
        "    random_output = target_tensor_val[k]\n",
        "    random_input = np.expand_dims(random_input,0)\n",
        "    result, sentence, attention_plot = evaluate(random_input, encoder, decoder, inp_lang, targ_lang, max_length_inp, max_length_targ)\n",
        "    print('Input: {}'.format(sentence[8:-6]))\n",
        "    print('Predicted translation: {}'.format(result[:-6]))\n",
        "    for i in random_output:\n",
        "        if i == 0:\n",
        "            break\n",
        "        actual_sent = actual_sent + targ_lang.idx2word[i] + ' '\n",
        "    actual_sent = actual_sent[8:-7]\n",
        "    print('Actual translation: {}'.format(actual_sent))\n",
        "    attention_plot = attention_plot[:len(result.split(' '))-2, 1:len(sentence.split(' '))-1]\n",
        "    sentence, result = sentence.split(' '), result.split(' ')\n",
        "    sentence = sentence[1:-1]\n",
        "    result = result[:-2]\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-04-21T20:56:46.087891Z",
          "iopub.status.busy": "2024-04-21T20:56:46.087192Z",
          "iopub.status.idle": "2024-04-21T20:56:46.148170Z",
          "shell.execute_reply": "2024-04-21T20:56:46.147563Z"
        },
        "papermill": {
          "duration": 0.133767,
          "end_time": "2024-04-21T20:56:46.148287",
          "exception": false,
          "start_time": "2024-04-21T20:56:46.014520",
          "status": "completed"
        },
        "tags": [],
        "id": "yB37GW26WA7j",
        "outputId": "13390150-38b8-4a47-cef9-a91ce9bc0e33"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input: no one except allah can bring it forth and establish\n",
            "Predicted translation: اور وہ لوگ اس کے لئے ہے \n",
            "Actual translation: اﷲ کے سوا اسے کوئی ظاہر اور قائم کرنے والا نہیں ہے\n"
          ]
        }
      ],
      "source": [
        "predict_random_val_sentence()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "papermill": {
          "duration": 0.070692,
          "end_time": "2024-04-21T20:56:52.681924",
          "exception": false,
          "start_time": "2024-04-21T20:56:52.611232",
          "status": "completed"
        },
        "tags": [],
        "id": "TspIK-7dWA7k"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "datasetId": 4845971,
          "sourceId": 8184292,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30042,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "papermill": {
      "duration": 18849.064149,
      "end_time": "2024-04-21T20:56:52.959083",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2024-04-21T15:42:43.894934",
      "version": "2.1.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}